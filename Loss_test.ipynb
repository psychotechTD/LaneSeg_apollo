{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import make_data_loader, make_data_loader2\n",
    "from modeling.deeplab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ÊûÑÂª∫args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"PyTorch DeeplabV3Plus Training\")\n",
    "parser.add_argument('--backbone', type=str, default='mobilenet',\n",
    "                    choices=['resnet', 'xception', 'drn', 'mobilenet'],\n",
    "                    help='backbone name (default: resnet)')\n",
    "parser.add_argument('--out-stride', type=int, default=16,\n",
    "                    help='network output stride (default: 8)')\n",
    "parser.add_argument('--dataset', type=str, default='apollo',\n",
    "                    choices=['apollo'],\n",
    "                    help='dataset name (default: apollo)')\n",
    "\n",
    "parser.add_argument('--sync-bn', type=bool, default=None,\n",
    "                    help='whether to use sync bn (default: auto)')\n",
    "parser.add_argument('--freeze-bn', type=bool, default=False,\n",
    "                    help='whether to freeze bn parameters (default: False)')\n",
    "parser.add_argument('--loss-type', type=str, default='diceplusce',\n",
    "                    choices=['ce', 'focal', 'dice', 'diceplusce'],\n",
    "                    help='loss func type (default: ce)')\n",
    "# training hyper params\n",
    "parser.add_argument('--batch-size', type=int, default=None,\n",
    "                    metavar='N', help='input batch size for \\\n",
    "                            training (default: auto)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=None,\n",
    "                    metavar='N', help='input batch size for \\\n",
    "                                testing (default: auto)')\n",
    "\n",
    "# cuda, seed and logging\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--gpu-ids', type=str, default='0',\n",
    "                    help='use which gpu to train, must be a \\\n",
    "                    comma-separated list of integers only (default=0)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "# checking point\n",
    "parser.add_argument('--resume', type=str, default=None,\n",
    "                    help='put the path to resuming file if needed')\n",
    "parser.add_argument('--checkname', type=str, default=None,\n",
    "                    help='set the checkpoint name')\n",
    "# finetuning pre-trained models\n",
    "parser.add_argument('--ft', action='store_true', default=False,\n",
    "                    help='finetuning on a different dataset')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if args.cuda:\n",
    "    try:\n",
    "        args.gpu_ids = [int(s) for s in args.gpu_ids.split(',')]\n",
    "    except ValueError:\n",
    "        raise ValueError('Argument --gpu_ids must be a comma-separated list of integers only')\n",
    "\n",
    "if args.sync_bn is None:\n",
    "    if args.cuda and len(args.gpu_ids) > 1:\n",
    "        args.sync_bn = True\n",
    "    else:\n",
    "        args.sync_bn = False\n",
    "\n",
    "\n",
    "if args.batch_size is None:\n",
    "    args.batch_size = 4 * len(args.gpu_ids)  # Ê≠§Â§Ñ‰øÆÊîπbatch_size\n",
    "\n",
    "if args.test_batch_size is None:\n",
    "    args.test_batch_size = args.batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### È¶ñÂÖàÊûÑÂª∫ËæìÂÖ•predictionÂíåtarget,„ÄÄÁÑ∂ÂêéÂÅöÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen, test_gen, nclass = make_data_loader2(args)\n",
    "\n",
    "train_dir = './data_list/train_lite.csv'\n",
    "train_list = pd.read_csv(train_dir)\n",
    "val_dir = './data_list/val_lite.csv'\n",
    "val_list = pd.read_csv(val_dir)\n",
    "train_length = len(train_list)\n",
    "val_length = len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLab(num_classes=nclass,\n",
    "                backbone=args.backbone,\n",
    "                output_stride=args.out_stride,\n",
    "                sync_bn=args.sync_bn,\n",
    "                freeze_bn=args.freeze_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595.75"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_img_tr = train_length / args.batch_size\n",
    "num_img_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(1):\n",
    "    samples = next(train_gen)\n",
    "    image, target = samples['image'], samples['label']\n",
    "    image, target = image.cuda(), target.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Âú®Êó†ÂàùÂßãÂåñÊù°‰ª∂‰∏ãË∞ÉÁî®Ê®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 384, 1024])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384, 1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './run/apollo/deeplab-mobilenet/model_best.pth (0.79v100).tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_trained = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384, 1024])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4,    8,  384, 1024])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(output_trained.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ÊµãËØïÂêÑÁßçloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4874, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4874, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.backward()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### LogSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "logsoftmax‰∏çÊîπÂèòÂ∞∫ÂØ∏ÔºåÊ≥®ÊÑè‰∏çÂêådimÁöÑÂê´‰πâÔºåÂèÇÁÖßhttps://blog.csdn.net/sunyueqinghit/article/details/101113251\n",
    "‰ª•Âèähttps://www.cnblogs.com/jeshy/p/10933882.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4283,  1.5400, -0.8837, -0.5143],\n",
       "         [-0.0508, -0.4953,  0.1950, -0.2600],\n",
       "         [ 0.2361, -1.4963,  1.8959,  1.6305]],\n",
       "\n",
       "        [[-0.8789, -0.0157, -1.1951, -0.2315],\n",
       "         [ 0.3002, -1.2076, -0.1301,  0.2501],\n",
       "         [-0.9789, -1.0403, -0.5214,  0.6075]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=0)\n",
    "input = torch.randn(2, 3, 4)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2395, -0.1915, -0.5495, -0.8445],\n",
       "         [-0.8839, -0.3991, -0.5438, -0.9804],\n",
       "         [-0.2598, -0.9469, -0.0854, -0.3071]],\n",
       "\n",
       "        [[-1.5467, -1.7472, -0.8609, -0.5617],\n",
       "         [-0.5330, -1.1114, -0.8688, -0.4703],\n",
       "         [-1.4749, -0.4909, -2.5027, -1.3301]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8939, -0.1644, -2.9984, -2.3823],\n",
       "         [-1.3729, -2.1997, -1.9197, -2.1280],\n",
       "         [-1.0860, -3.2007, -0.2188, -0.2375]],\n",
       "\n",
       "        [[-1.6402, -0.5084, -1.7686, -1.5959],\n",
       "         [-0.4611, -1.7003, -0.7035, -1.1143],\n",
       "         [-1.7402, -1.5329, -1.0949, -0.7569]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/.conda/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2395, -0.1915, -0.5495, -0.8445],\n",
       "         [-0.8839, -0.3991, -0.5438, -0.9804],\n",
       "         [-0.2598, -0.9469, -0.0854, -0.3071]],\n",
       "\n",
       "        [[-1.5467, -1.7472, -0.8609, -0.5617],\n",
       "         [-0.5330, -1.1114, -0.8688, -0.4703],\n",
       "         [-1.4749, -0.4909, -2.5027, -1.3301]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LogSoftmax()\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "output = loss(m(input), target)\n",
    "output.backward()\n",
    "\n",
    "# 2D loss example (used, for example, with image inputs)\n",
    "N, C = 5, 4\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C x height x width\n",
    "data = torch.randn(N, 16, 10, 10)\n",
    "conv = nn.Conv2d(16, C, (3, 3))\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
    "output = loss(m(conv(data)), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice Loss(Ëá™Â∑±ÂÜôÁöÑ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice lossÁöÑËæìÂÖ•inputÂíåtargetË¶ÅÊ±ÇÂêåÂΩ¢Áä∂ÔºåCrossEntropyÁöÑinput‰∏≠ÔºåpredÂíåtargetÁöÑÂΩ¢Áä∂ÂàÜÂà´‰∏∫Ôºª4,8,384,1024],Ôºª4,384,1024ÔºΩ\n",
    "ÊâÄ‰ª•ÈúÄË¶ÅÂØπtargetÂÅöone_hotÁºñÁ†ÅÔºåÂ∞ÜÂÖ∂ÂΩ¢Áä∂Âèò‰∏∫[4,8,384,1024],Âú®ËÆ°ÁÆódice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One compelling reason for using cross-entropy over dice-coefficient or the similar IoU metric is that the gradients are nicer.\n",
    "\n",
    "The gradients of cross-entropy wrt the logits is something like ùëù‚àíùë°, where ùëù is the softmax outputs and ùë° is the target. Meanwhile, if we try to write the dice coefficient in a differentiable form: 2ùëùùë°ùëù2+ùë°2 or 2ùëùùë°ùëù+ùë°, then the resulting gradients wrt ùëù are much uglier: 2ùë°(ùë°2‚àíùëù2)(ùëù2+ùë°2)2 and 2ùë°2(ùëù+ùë°)2. It's easy to imagine a case where both ùëù and ùë° are small, and the gradient blows up to some huge value. In general, it seems likely that training will become more unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### one_hotÁºñÁ†ÅËΩ¨Êç¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏ÄËà¨Áî®scatterÁîüÊàêone_hotÂêëÈáè,„ÄÄÊµãËØïÂ¶Ç‰∏ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor([[[0,0],[1,0]], [[0,2],[1,0]], [[0,1],[0,0]], [[3,0],[0,0]]])\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0],\n",
       "          [1, 0]]],\n",
       "\n",
       "\n",
       "        [[[0, 2],\n",
       "          [1, 0]]],\n",
       "\n",
       "\n",
       "        [[[0, 1],\n",
       "          [0, 0]]],\n",
       "\n",
       "\n",
       "        [[[3, 0],\n",
       "          [0, 0]]]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = index.unsqueeze(dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [0., 1.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0.],\n",
      "          [0., 1.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[0., 1.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[0., 1.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[1., 0.],\n",
      "          [0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "onehot = torch.zeros(4, 4, 2, 2)\n",
    "onehot.scatter_(1, index, 1)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.) tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(onehot.sum(), index.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384, 1024])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1572864.)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = target.unsqueeze(dim=1)\n",
    "onehot = torch.zeros(4,8,384,1024)\n",
    "onehot.scatter_(1,index.cpu().long(),1)\n",
    "onehot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572864"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*384*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(input, num_classes):\n",
    "    \"\"\"Convert class index tensor to one hot encoding tensor.\n",
    "    Args:\n",
    "         input: A tensor of shape [N, 1, *]\n",
    "         num_classes: An int of number of class\n",
    "    Returns:\n",
    "        A tensor of shape [N, num_classes, *]\n",
    "    \"\"\"\n",
    "    shape = np.array(input.shape)\n",
    "    shape[1] = num_classes\n",
    "    shape = tuple(shape)\n",
    "    result = torch.zeros(shape)\n",
    "    result = result.scatter_(1, input.cpu(), 1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 384, 1024])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 384, 1024])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = make_one_hot(target.long().unsqueeze(dim=1), 8)\n",
    "target_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(81749., device='cuda:0')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1572864., device='cuda:0')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_onehot = target_onehot.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryDiceLoss(logit, target, smooth=1, p=2, reduction='mean'):\n",
    "    logit = logit.contiguous().view(logit.shape[0], -1)\n",
    "    target = target.contiguous().view(target.shape[0], -1)\n",
    "    num = 2*torch.sum(torch.mul(logit, target), dim=1) + smooth\n",
    "    den = torch.sum(logit.pow(p) + target.pow(p), dim=1) + smooth\n",
    "\n",
    "    loss = 1 - num / den\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def DiceLoss(logit, target):\n",
    "    total_loss = 0\n",
    "    logit = F.softmax(logit, dim=1)\n",
    "    for i in range(logit.shape[1]):\n",
    "        dice_loss = BinaryDiceLoss(logit[:, i], target[:, i])\n",
    "        total_loss += dice_loss\n",
    "    return total_loss/target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(53.6216, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_trained.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DiceLoss(output_trained, target_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "463.722px",
    "left": "1361.82px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
